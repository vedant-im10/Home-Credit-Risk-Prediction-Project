{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "926a9f30",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.00363,
     "end_time": "2024-05-08T03:00:45.610892",
     "exception": false,
     "start_time": "2024-05-08T03:00:45.607262",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Initial Submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "256a16b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T03:00:45.619940Z",
     "iopub.status.busy": "2024-05-08T03:00:45.619216Z",
     "iopub.status.idle": "2024-05-08T03:00:50.348724Z",
     "shell.execute_reply": "2024-05-08T03:00:50.347561Z"
    },
    "papermill": {
     "duration": 4.737338,
     "end_time": "2024-05-08T03:00:50.351685",
     "exception": false,
     "start_time": "2024-05-08T03:00:45.614347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import roc_auc_score, f1_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "# SET HERE\n",
    "train_directory = '/kaggle/input/home-credit-credit-risk-model-stability/parquet_files/train/'\n",
    "test_directory = '/kaggle/input/home-credit-credit-risk-model-stability/parquet_files/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa17162a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T03:00:50.360588Z",
     "iopub.status.busy": "2024-05-08T03:00:50.359981Z",
     "iopub.status.idle": "2024-05-08T03:00:50.380290Z",
     "shell.execute_reply": "2024-05-08T03:00:50.378475Z"
    },
    "papermill": {
     "duration": 0.0283,
     "end_time": "2024-05-08T03:00:50.383471",
     "exception": false,
     "start_time": "2024-05-08T03:00:50.355171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def aggregate(df):\n",
    "    '''\n",
    "    Defines aggregation style for group 1 and 2 datasets. take mean of numerics and max + min of strings\n",
    "    '''\n",
    "    \n",
    "    num_cols = [c for c in df.columns if c[-1] in ['P', 'A']]\n",
    "    other_cols = [c for c in df.columns if c[-1] not in ['P', 'A']]\n",
    "\n",
    "    num_agg_mean = [pl.mean(c).alias('mean_' + c) for c in num_cols]\n",
    "    num_agg_max = [pl.max(c).alias('max_' + c) for c in num_cols]\n",
    "    num_agg_min = [pl.min(c).alias('min_' + c) for c in num_cols]\n",
    "    str_agg_max = [pl.max(c).alias('max_' + c) for c in other_cols if c not in ['case_id', 'num_group1', 'num_group2']]\n",
    "    str_agg_min = [pl.min(c).alias('min_' + c) for c in other_cols if c not in ['case_id', 'num_group1', 'num_group2']]\n",
    "    \n",
    "#     agg = num_agg_mean + num_agg_max + num_agg_min + str_agg_max + str_agg_min\n",
    "    agg = num_agg_mean + str_agg_max\n",
    "    return agg\n",
    "\n",
    "    \n",
    "def set_datatypes(df):\n",
    "    '''\n",
    "    Tests column data type and reformats.\n",
    "    '''\n",
    "    \n",
    "    for c in df.columns:\n",
    "        if c in ['case_id', 'WEEK_NUM', 'num_group1', 'num_group2']: # excl MONTH\n",
    "            df = df.with_columns(pl.col(c).cast(pl.Int64))\n",
    "        # elif col in ['date_decision']:\n",
    "        #     df = df.with_columns(pl.col(c).cast(pl.Date))\n",
    "        elif c[-1] in ['P', 'A'] or c == 'target':\n",
    "            df = df.with_columns(pl.col(c).cast(pl.Float64))\n",
    "        elif c[-1] == 'M' or c == 'MONTH':\n",
    "            df = df.with_columns(pl.col(c).cast(pl.String))\n",
    "        elif c[-1] == 'D' or c == 'date_decision':\n",
    "            df = df.with_columns(pl.col(c).cast(pl.Date).dt.truncate('1mo'))\n",
    "        # else:\n",
    "        #     print('column {c} is unknown datatype'.format(c=c))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def reduce_columns(df):\n",
    "    '''\n",
    "    Tests for columns with many nulls or string columns with only 1 or many many values.\n",
    "    '''\n",
    "    \n",
    "    for c in df.columns:\n",
    "        p_null = df[c].is_null().mean() >= 0.70\n",
    "        uniq = df[c].n_unique() == 1 or df[c].n_unique() > 200\n",
    "        \n",
    "        if c in ['target', 'case_id', 'MONTH']:\n",
    "            pass\n",
    "        elif p_null:\n",
    "            df = df.drop(c)\n",
    "        elif c[-1] == 'M' and uniq:\n",
    "            df = df.drop(c)\n",
    "        elif c[-1] == 'D' or c in ['WEEK_NUM', 'date_decision']:\n",
    "            df = df.drop(c) # for now\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def load_from_parquet(path, source):\n",
    "    '''\n",
    "    Loads a parquet file at a path and does some formatting. If path includes a set of tables,\n",
    "    load each and then concat them together. Also determine if the table is of depth 0. if \n",
    "    not, perform aggregation.\n",
    "    '''\n",
    "\n",
    "    # if split into multiple tables, first combine. tested, and separate files shouldn't have\n",
    "    # any overlap with case_id\n",
    "    if type(path) == list:\n",
    "        d0 = 'static_0' in path[0] or 'static_cb_0' in path[0] or '_base' in path[0]\n",
    "        tot = []\n",
    "        for t in path:\n",
    "            d = pl.read_parquet(source+t)\n",
    "            d = set_datatypes(d)\n",
    "            if not d0:\n",
    "                d = d.group_by('case_id').agg(aggregate(d))\n",
    "            tot.append(d)\n",
    "\n",
    "        # combine\n",
    "        df = pl.concat(tot, how='vertical_relaxed')\n",
    "\n",
    "    else:\n",
    "        d0 = 'static_0' in path or 'static_cb_0' in path or '_base' in path\n",
    "        df = pl.read_parquet(source+path)\n",
    "        df = set_datatypes(df)\n",
    "        if not d0:\n",
    "            df = df.group_by('case_id').agg(aggregate(df))\n",
    "\n",
    "    # only need to do this for training. later, i'll make sure train and test have the same cols\n",
    "    if 'train' in source:\n",
    "        df = reduce_columns(df) # do this after aggregation, if it occurs\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69ce6c00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T03:00:50.393127Z",
     "iopub.status.busy": "2024-05-08T03:00:50.391864Z",
     "iopub.status.idle": "2024-05-08T03:00:50.400749Z",
     "shell.execute_reply": "2024-05-08T03:00:50.399706Z"
    },
    "papermill": {
     "duration": 0.016488,
     "end_time": "2024-05-08T03:00:50.403491",
     "exception": false,
     "start_time": "2024-05-08T03:00:50.387003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_tables = [\n",
    "    'train_base.parquet',\n",
    "    ['train_applprev_1_0.parquet', 'train_applprev_1_1.parquet'],\n",
    "    'train_applprev_2.parquet',\n",
    "    ['train_credit_bureau_a_1_0.parquet', 'train_credit_bureau_a_1_1.parquet', 'train_credit_bureau_a_1_2.parquet', 'train_credit_bureau_a_1_3.parquet'],\n",
    "    ['train_credit_bureau_a_2_0.parquet', 'train_credit_bureau_a_2_1.parquet', 'train_credit_bureau_a_2_2.parquet', 'train_credit_bureau_a_2_3.parquet', 'train_credit_bureau_a_2_4.parquet', 'train_credit_bureau_a_2_5.parquet', 'train_credit_bureau_a_2_6.parquet', 'train_credit_bureau_a_2_7.parquet', 'train_credit_bureau_a_2_8.parquet', 'train_credit_bureau_a_2_9.parquet', 'train_credit_bureau_a_2_10.parquet'],\n",
    "    'train_credit_bureau_b_1.parquet',\n",
    "    'train_credit_bureau_b_2.parquet',\n",
    "    'train_debitcard_1.parquet',\n",
    "    'train_deposit_1.parquet',\n",
    "    'train_other_1.parquet',\n",
    "    'train_person_1.parquet',\n",
    "    'train_person_2.parquet',\n",
    "    ['train_static_0_0.parquet', 'train_static_0_1.parquet'],\n",
    "    'train_static_cb_0.parquet',\n",
    "    'train_tax_registry_a_1.parquet',\n",
    "    'train_tax_registry_b_1.parquet',\n",
    "    'train_tax_registry_c_1.parquet'\n",
    "]\n",
    "\n",
    "test_tables = [\n",
    "    'test_base.parquet',\n",
    "    ['test_applprev_1_0.parquet', 'test_applprev_1_1.parquet', 'test_applprev_1_2.parquet'],\n",
    "    'test_applprev_2.parquet',\n",
    "    ['test_credit_bureau_a_1_0.parquet', 'test_credit_bureau_a_1_1.parquet', 'test_credit_bureau_a_1_2.parquet', 'test_credit_bureau_a_1_3.parquet', 'test_credit_bureau_a_1_4.parquet'],\n",
    "    ['test_credit_bureau_a_2_0.parquet', 'test_credit_bureau_a_2_1.parquet', 'test_credit_bureau_a_2_2.parquet', 'test_credit_bureau_a_2_3.parquet', 'test_credit_bureau_a_2_4.parquet', 'test_credit_bureau_a_2_5.parquet', 'test_credit_bureau_a_2_6.parquet', 'test_credit_bureau_a_2_7.parquet', 'test_credit_bureau_a_2_8.parquet', 'test_credit_bureau_a_2_9.parquet', 'test_credit_bureau_a_2_10.parquet', 'test_credit_bureau_a_2_11.parquet'],\n",
    "    'test_credit_bureau_b_1.parquet',\n",
    "    'test_credit_bureau_b_2.parquet',\n",
    "    'test_debitcard_1.parquet',\n",
    "    'test_deposit_1.parquet',\n",
    "    'test_other_1.parquet',\n",
    "    'test_person_1.parquet',\n",
    "    'test_person_2.parquet',\n",
    "    ['test_static_0_0.parquet', 'test_static_0_1.parquet', 'test_static_0_2.parquet'],\n",
    "    'test_static_cb_0.parquet',\n",
    "    'test_tax_registry_a_1.parquet',\n",
    "    'test_tax_registry_b_1.parquet',\n",
    "    'test_tax_registry_c_1.parquet'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d7595e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T03:00:50.413926Z",
     "iopub.status.busy": "2024-05-08T03:00:50.412827Z",
     "iopub.status.idle": "2024-05-08T03:03:33.643796Z",
     "shell.execute_reply": "2024-05-08T03:03:33.642415Z"
    },
    "papermill": {
     "duration": 163.242626,
     "end_time": "2024-05-08T03:03:33.650291",
     "exception": false,
     "start_time": "2024-05-08T03:00:50.407665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape:\t (1526659, 325)\n",
      "test data shape:\t (10, 324)\n"
     ]
    }
   ],
   "source": [
    "# actually load data from location\n",
    "\n",
    "# start with training data\n",
    "train_data = load_from_parquet(train_tables[0], train_directory)\n",
    "for t in train_tables[1:]:\n",
    "    # print('\\n', t)\n",
    "    train_data = train_data.join(load_from_parquet(t, train_directory), on='case_id', how='left')\n",
    "\n",
    "gc.collect()\n",
    "    \n",
    "# test data\n",
    "test_data = load_from_parquet(test_tables[0], test_directory)\n",
    "for t in test_tables[1:]:\n",
    "    # print('\\n', t)\n",
    "    test_data = test_data.join(load_from_parquet(t, test_directory), on='case_id', how='left')\n",
    "\n",
    "# make sure test and training have same columns\n",
    "test_data = test_data.select([c for c in train_data.columns if c != 'target'])\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print('train data shape:\\t', train_data.shape)\n",
    "print('test data shape:\\t', test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69b173d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T03:03:33.659141Z",
     "iopub.status.busy": "2024-05-08T03:03:33.658693Z",
     "iopub.status.idle": "2024-05-08T03:04:06.918970Z",
     "shell.execute_reply": "2024-05-08T03:04:06.916499Z"
    },
    "papermill": {
     "duration": 33.269866,
     "end_time": "2024-05-08T03:04:06.923666",
     "exception": false,
     "start_time": "2024-05-08T03:03:33.653800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert datasets to pandas, using category dtype where relevant\n",
    "\n",
    "train_data = train_data.to_pandas()#.sample(750000)\n",
    "obj_cols = list(train_data.select_dtypes('object').columns)\n",
    "train_data[obj_cols] = train_data[obj_cols].astype('category')\n",
    "\n",
    "test_data = test_data.to_pandas()\n",
    "test_data[obj_cols] = test_data[obj_cols].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96a7a867",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T03:04:06.935429Z",
     "iopub.status.busy": "2024-05-08T03:04:06.934935Z",
     "iopub.status.idle": "2024-05-08T03:06:41.569865Z",
     "shell.execute_reply": "2024-05-08T03:06:41.569096Z"
    },
    "papermill": {
     "duration": 154.646995,
     "end_time": "2024-05-08T03:06:41.576123",
     "exception": false,
     "start_time": "2024-05-08T03:04:06.929128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 33603, number of negative: 1035058\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.753610 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 38271\n",
      "[LightGBM] [Info] Number of data points in the train set: 1068661, number of used features: 321\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.031444 -> initscore=-3.427597\n",
      "[LightGBM] [Info] Start training from score -3.427597\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "# train_data = train_data.to_pandas()\n",
    "# test_data = test_data.to_pandas()\n",
    "# cat_features = train_data.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# # Fill NaN values with a placeholder string such as 'missing'\n",
    "# train_data[cat_features] = train_data[cat_features].fillna('missing')\n",
    "# test_data[cat_features] = test_data[cat_features].fillna('missing')\n",
    "\n",
    "# # Convert all categorical features to type 'category'\n",
    "# train_data[cat_features] = train_data[cat_features].astype('category')\n",
    "# test_data[cat_features] = test_data[cat_features].astype('category')\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    train_data.drop(columns=['target', 'case_id']),\n",
    "    train_data['target'], \n",
    "    test_size=0.3, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "del train_data\n",
    "gc.collect()\n",
    "\n",
    "# ros = RandomOverSampler(random_state=0, sampling_strategy=0.3)\n",
    "# x_train, y_train = ros.fit_resample(x_train, y_train)\n",
    "\n",
    "# params = {\n",
    "#     \"boosting_type\": \"gbdt\",\n",
    "#     \"metric\": \"auc\",\n",
    "#     \"max_depth\": 10,  \n",
    "#     \"learning_rate\": 0.05,\n",
    "#     \"n_estimators\": 2000,  \n",
    "#     \"colsample_bytree\": 0.8,\n",
    "#     \"colsample_bynode\": 0.8,\n",
    "#     \"reg_alpha\": 0.1,\n",
    "#     \"reg_lambda\": 10,\n",
    "#     'num_leaves':64\n",
    "# }\n",
    "\n",
    "m = lgb.LGBMClassifier()\n",
    "m.fit(x_train, y_train, eval_set=[(x_val, y_val)])\n",
    "\n",
    "# cat_features_indices = [train_data.columns.get_loc(c) for c in cat_features if c in train_data]\n",
    "\n",
    "# m = CatBoostClassifier(\n",
    "#     iterations=3000, \n",
    "#     learning_rate=0.03, \n",
    "#     depth=6,\n",
    "#     cat_features=cat_features_indices,\n",
    "#     eval_metric='AUC',\n",
    "#     verbose=300\n",
    "# )\n",
    "# m.fit(x_train, y_train, eval_set=[(x_val, y_val)])\n",
    "\n",
    "# print('mean AUC score: {s}'.format(s=np.mean([np.mean(m.evals_result_['valid_0']['auc']) for m in models])))\n",
    "#print('mean LL score: {s}'.format(s=np.mean(m.evals_result_['valid_0']['binary_logloss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbb27033",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T03:06:41.585749Z",
     "iopub.status.busy": "2024-05-08T03:06:41.585154Z",
     "iopub.status.idle": "2024-05-08T03:06:41.589283Z",
     "shell.execute_reply": "2024-05-08T03:06:41.588114Z"
    },
    "papermill": {
     "duration": 0.011555,
     "end_time": "2024-05-08T03:06:41.591472",
     "exception": false,
     "start_time": "2024-05-08T03:06:41.579917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lgb.plot_importance(m, importance_type=\"split\", figsize=(10,50))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d00aae41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T03:06:41.601391Z",
     "iopub.status.busy": "2024-05-08T03:06:41.600776Z",
     "iopub.status.idle": "2024-05-08T03:06:41.674584Z",
     "shell.execute_reply": "2024-05-08T03:06:41.673643Z"
    },
    "papermill": {
     "duration": 0.081526,
     "end_time": "2024-05-08T03:06:41.676997",
     "exception": false,
     "start_time": "2024-05-08T03:06:41.595471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prepare to make predictions\n",
    "inds = test_data['case_id']\n",
    "test = test_data.drop(columns=['case_id'])\n",
    "\n",
    "# make predictions on trained model\n",
    "predictions = m.predict_proba(test)[:, 1]\n",
    "\n",
    "out = pd.DataFrame(columns=['case_id', 'score'])\n",
    "out['case_id'] = inds\n",
    "out['score'] = predictions\n",
    "out = out.set_index('case_id')\n",
    "\n",
    "out.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab763c1",
   "metadata": {
    "papermill": {
     "duration": 0.005765,
     "end_time": "2024-05-08T03:06:41.686940",
     "exception": false,
     "start_time": "2024-05-08T03:06:41.681175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7921029,
     "sourceId": 50160,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30684,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 360.088192,
   "end_time": "2024-05-08T03:06:42.717473",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-08T03:00:42.629281",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
